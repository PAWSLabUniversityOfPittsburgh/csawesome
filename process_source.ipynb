{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk,path\n",
    "from os.path import join\n",
    "from nltk import word_tokenize\n",
    "\n",
    "file_text = {}\n",
    "\n",
    "for root,curr_dir,files in walk('./_sources'):\n",
    "    for file in files:\n",
    "        with open(join(root,file),'r',errors='ignore') as f:\n",
    "            if path.splitext(file)[1] == '.rst' and \\\n",
    "                'unit' in root.strip().lower() and \\\n",
    "                'topic' in file.strip().lower():\n",
    "                file_text[path.splitext(file)[0].strip().lower()] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_read_count(rst_text):\n",
    "    rst_text = rst_text.strip().lower()\n",
    "    line_count = 0\n",
    "    rst_text_lines = rst_text.splitlines()\n",
    "    act_list = ['mchoice','hparsons','activecode','parsonsprob','fillintheblank','shortanswer','youtube']\n",
    "\n",
    "    for line in rst_text_lines:\n",
    "        match_count = 0\n",
    "        for token in word_tokenize(line.strip().lower()):\n",
    "            if token in act_list:\n",
    "                match_count += 1\n",
    "        \n",
    "        ## if match_count remains zero\n",
    "        if match_count == 0:\n",
    "            line_count += 1\n",
    "    # if there are lines to read in the page the count the page for reading\n",
    "    return 1 if line_count > 0 else 0\n",
    "\n",
    "\n",
    "def process_video_count(rst_text):\n",
    "    rst_text = rst_text.strip().lower()\n",
    "    video_count = 0\n",
    "    rst_text_lines = rst_text.splitlines()\n",
    "    for line in rst_text_lines:\n",
    "        if 'youtube' in line.strip().lower():\n",
    "            video_count += 1\n",
    "    return video_count\n",
    "\n",
    "def process_act_count(rst_text):\n",
    "    rst_text = rst_text.strip().lower()\n",
    "    rst_text_lines = rst_text.splitlines()\n",
    "    act_list = ['mchoice','hparsons','activecode','parsonsprob','fillintheblank','shortanswer']\n",
    "    act_count = 0\n",
    "    for line in rst_text_lines:\n",
    "        for token in word_tokenize(line.strip().lower()):\n",
    "            if token in act_list:\n",
    "                act_count += 1\n",
    "\n",
    "    return act_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\"Level..Chapter.\":list(file_text.keys()),\n",
    "                             \"page_count\":list([process_read_count(x) for x in file_text.values()]),\n",
    "                             \"video_count\":list([process_video_count(x) for x in file_text.values()]),\n",
    "                             \"act_count\":list([process_act_count(x) for x in file_text.values()])\n",
    "                             })\n",
    "df = df.sort_values('Level..Chapter.')\n",
    "df.loc[:,'page_counter'] = df['page_count'].cumsum()\n",
    "df.loc[:,'video_counter'] = df['video_count'].cumsum()\n",
    "df.loc[:,'act_counter'] = df['act_count'].cumsum()\n",
    "\n",
    "df.to_csv('./csawesome_page_act_video_counts_per_page.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
